{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imorting all the necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import folium\n",
    "import random as r\n",
    "import spacy\n",
    "import time\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "from math import sin, cos, sqrt, atan2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the database\n",
    "\n",
    "connection = psycopg2.connect(\n",
    "    host = 'wh-pg-db.c8t3ik4p6f7t.us-east-2.rds.amazonaws.com',\n",
    "    user = 'postgres',\n",
    "    password = 'jNbZoN04gyzzyWdGT2ZU',\n",
    "    database='whod'\n",
    "    )\n",
    "cursor=connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all the tables related to the candidate \n",
    "\n",
    "candidateSkills = pd.read_sql('select * from \"CandidateSkills\"', connection)\n",
    "Skills = pd.read_sql('select * from \"Skills\"', connection)\n",
    "SkillCategories = pd.read_sql('select * from \"SkillCategories\"', connection)\n",
    "\n",
    "\n",
    "# convertingt the geolocation in to proper redable form and importing it\n",
    "\n",
    "candidateLocation = pd.read_sql('select st_astext(location) from \"Candidates\"', connection)\n",
    "candidates['location']=candidateLocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the longitude and latitude from the location column and placing them into seperate columns\n",
    "\n",
    "long = candidates['location'].str.split('(').str[1].str.split(')').str[0].str.split(' ').str[0]\n",
    "lat = candidates['location'].str.split('(').str[1].str.split(')').str[0].str.split(' ').str[1]\n",
    "\n",
    "\n",
    "# converting the longitude and latitude to float \n",
    "\n",
    "candidates.long = candidates.long.astype('float')\n",
    "candidates.lat = candidates.lat.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extarcting meaningfull skills from the skills table and removing any garbage values\n",
    "\n",
    "skills_list = Skills[Skills.name.str[4].notnull()].name\n",
    "skills_list.index = range(0,len(skills_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling missing skills in candidate table using random skills from table skills\n",
    "\n",
    "for i in candidates[candidates.details.isnull()].index:\n",
    "    candidates.details[i] = skills_list[r.randint(0,208)]\n",
    "\n",
    "\n",
    "# filling latitude and longitude missing values using random values which are within the US coordinates \n",
    "    \n",
    "for i in candidates[candidates.long.isnull()].index:\n",
    "    candidates.long[i] = r.randint(34000000,47000000)/1000000\n",
    "    candidates.lat[i] = r.randint(92000000,120000000)/1000000    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the files for jobs\n",
    "\n",
    "job = pd.read_sql('SELECT * FROM \"Jobs\"',connection)\n",
    "site = pd.read_sql('SELECT * FROM \"Sites\"',connection)\n",
    "\n",
    "\n",
    "# removing unnecessary columns from site\n",
    "\n",
    "site = site.iloc[:,[0,2,3]]\n",
    "\n",
    "\n",
    "# importing latitude and longitude in readable format\n",
    "\n",
    "site_location = pd.read_sql('select st_astext(location) from \"Sites\"',connection)\n",
    "site['location'] = site_location\n",
    "\n",
    "\n",
    "# merging job with the respective location using siteId\n",
    "\n",
    "job_merged = job.merge(site ,how = 'left',on = 'siteId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extarcting the longitude and latitude from location\n",
    "\n",
    "long = job_merged['location'].str.split('(').str[1].str.split(')').str[0].str.split(' ').str[0]\n",
    "lat = job_merged['location'].str.split('(').str[1].str.split(')').str[0].str.split(' ').str[1]\n",
    "\n",
    "\n",
    "# converting longitude and latitude to float \n",
    "\n",
    "job['long'] = long.astype('float')\n",
    "job['lat'] = lat.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling in missing value of latitude and longitude with random values with the US coodinates\n",
    "\n",
    "for i in job[job.long.isnull()].index:\n",
    "    job.long[i] = r.randint(34000000,47000000)/1000000\n",
    "    job.lat[i] = r.randint(92000000,120000000)/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing dublicate values and reorder the indexes based on Id\n",
    "\n",
    "candidates = candidates.drop_duplicates(subset = 'candidateId')\n",
    "candidates = candidates.sort_values('candidateId')\n",
    "candidates.index = candidates.candidateId\n",
    "job = job.sort_values('jobId')\n",
    "job.index = job.jobId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm for clustering similar skill together based on similarity score\n",
    "\n",
    "similarity_matrix = pd.DataFrame(index = candidates.candidateId, columns = candidates.candidateId)\n",
    "for i in candidates.candidateId:\n",
    "    print(i)\n",
    "    for j in candidates.candidateId:\n",
    "        similarity_matrix.loc[i,j] = nlp(candidates.details[j]).similarity(nlp(candidates.details[i]))\n",
    "        \n",
    "similarity_group = similarity_matrix[similarity_matrix>0.8].notnull().sum() # setting minimum similarity score at 0.8 \n",
    "\n",
    "sm = similarity_matrix.copy()\n",
    "i=0\n",
    "while(i<x):\n",
    "    indexes = sm[sm.iloc[:,i]>0.8][1:].index\n",
    "    sm.drop(indexes,axis=1,inplace=True,errors = 'ignore')\n",
    "    i=i+1\n",
    "    x = sm.shape[1]\n",
    "    \n",
    "sm_group = sm[sm>0.8].notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second variation of skill clustering algorithm, around 5-10 times faster\n",
    "\n",
    "similarity_matrix = pd.DataFrame(index = candidates.candidateId, columns = candidates.candidateId)\n",
    "i=0\n",
    "k=0\n",
    "while (k< similarity_matrix.shape[1]):\n",
    "    i = similarity_matrix.columns[k]\n",
    "    print(i)\n",
    "    for j in candidates.candidateId:\n",
    "        score = nlp(candidates.details[j]).similarity(nlp(candidates.details[i]))\n",
    "        if((score>0.8) & (i!=j)): # condition to cluster only those which have similarity score greater than 0.8\n",
    "            print('j',j)\n",
    "            similarity_matrix.loc[j,i] = score\n",
    "            similarity_matrix.drop(j,inplace=True,axis=1,errors='ignore')\n",
    "    k=k+1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the distance between 2 coordinates \n",
    "\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "def distance(lat1,lon1,lat2,lon2):\n",
    "    R = 6373.0\n",
    "    lat1 = radians(lat1)\n",
    "    lon1 = radians(lon1)\n",
    "    lat2 = radians(lat2)\n",
    "    lon2 = radians(lon2)\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = ((sin(dlat/2))**2) + (cos(lat1) * cos(lat2) * ((sin(dlon/2))**2))\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "    distance = R * c\n",
    "    \n",
    "    return distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre conversion of degrees to radians to save up time\n",
    "\n",
    "candidates['lat_rad'] = candidates.lat.map(radians)\n",
    "candidates['long_rad'] = candidates.long.map(radians)\n",
    "job['lat_rad'] = job.lat.map(radians)\n",
    "job['long_rad'] = job.long.map(radians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating candidates with candiates 130 times in a for loop to build 100,000 records for testing purpose\n",
    "\n",
    "cand_all = candidates\n",
    "for i in range(0,130):\n",
    "    cand_all = pd.concat([cand_all,candidates],axis=0)\n",
    "    \n",
    "\n",
    "# concatenating job with job to get large number of jobs for testing purpose\n",
    "    \n",
    "jo = job\n",
    "for i in range(0,1):\n",
    "    jo = pd.concat([jo,job],axis=0    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindexing the data and creating an empty dataframe to store all the scores\n",
    "\n",
    "cand=cand_all\n",
    "cand.index = range(0,len(cand))\n",
    "jo.index = range(0,len(jo))\n",
    "cand.candidateId = range(0,len(cand))\n",
    "jo.jobId = range(0,len(jo))\n",
    "df = pd.DataFrame(columns = sorted(jo.jobId), index = sorted(cand.candidateId))\n",
    "df.replace(np.nan,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm to match jobs with canddiates (version 1)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "df = pd.DataFrame(index = sorted(job.jobId), columns = sorted(candidates.candidateId))\n",
    "w_skill = 0.3  # weightage for skill\n",
    "w_distance = 0.7   # weightage for distance \n",
    "candidates.index = candidates.candidateId\n",
    "job.index = job.jobId\n",
    "for i in sorted(job.jobId)[:100]: # choosing 100 jobs for testing\n",
    "    for j in sorted(candidates.candidateId)[:500]: # choosing 500 jobs for testing\n",
    "        skill_score = nlp(candidates.loc[j,'details']).similarity(nlp(job.loc[i,'title'])) # calculating simialrity\n",
    "        dist = distance(candidates.loc[j,'long'],candidates.loc[j,'lat'],job.loc[i,'long'],job.loc[i,'lat']) # calling distance function\n",
    "        if(dist>500):  # condition for greater than 500 km\n",
    "            distance_score = 0\n",
    "        else:\n",
    "            distance_score = 1/(pow(dist,dist*0.005))\n",
    "        total_score = (skill_score*w_skill) + (distance_score*w_distance) # calculating total score\n",
    "        df.loc[i,j] = total_score\n",
    "        \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm to match jobs with canddiates (version 2)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "w_skill = 0.3\n",
    "w_distance = 0.7\n",
    "\n",
    "R = 6373.0\n",
    "cand = cand_all.copy()\n",
    "cand = cand[:10000] # selecting 10,000 candidates\n",
    "for i in sorted(jo.jobId)[:1]:\n",
    "    cand_filtered = cand[(cand.long<(jo.long[i]+1)) & (cand.long>(jo.long[i]-1)) &  # filtering based on coordinates\n",
    "                         (cand.lat<(jo.lat[i]+1)) & (cand.lat>(jo.lat[i]-1))]\n",
    "    for j in sorted(cand_filtered.candidateId):\n",
    "        if((abs(cand.loc[j,'long']-jo.loc[i,'long']) + abs(cand.loc[j,'lat']-jo.loc[i,'lat'])) > 1): # calculating rough distance\n",
    "            df.loc[j,i]  = 0\n",
    "        else:\n",
    "            skill_score = nlp(cand.loc[j,'details']).similarity(nlp(jo.loc[i,'title']))\n",
    "            dist = distance(cand.loc[j,'long'],cand.loc[j,'lat'],jo.loc[i,'long'],jo.loc[i,'lat']) # calling distance function\n",
    "            distance_score = 1/(pow(dist,dist*0.005))\n",
    "            df.loc[j,i]  = (skill_score*w_skill) + (distance_score*w_distance)\n",
    "        \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm to match jobs with canddiates (version 3)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "w_skill = 0.3\n",
    "w_distance = 0.7\n",
    "\n",
    "cand = cand_all.copy()\n",
    "cand = cand[:50000] # selecting 50,000 jobs\n",
    "i = sorted(jo.jobId)[2]\n",
    "cand_filtered = cand[(cand.long<(jo.long[i]+0.5)) & (cand.long>(jo.long[i]-0.5)) & \n",
    "                     (cand.lat<(jo.lat[i]+0.5)) & (cand.lat>(jo.lat[i]-0.5))]  # filtering based on coordinates \n",
    "\n",
    "for j in sorted(cand_filtered.candidateId):\n",
    "    skill_score = nlp(cand.details[j]).similarity(nlp(jo.title[i])) # calculating similarity score\n",
    "    dist = distance(cand.long_rad[j],cand.lat_rad[j],jo.long_rad[i],jo.lat_rad[i]) # calling distance function \n",
    "    distance_score = 1/(pow(dist,dist*0.005))\n",
    "    df.loc[j,i]  = (skill_score*w_skill) + (distance_score*w_distance) #  calculating total score\n",
    "        \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm to match jobs with canddiates (version 4)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "w_skill = 0.3\n",
    "w_distance = 0.7\n",
    "\n",
    "close_value=[]\n",
    "cand = cand_all.copy()\n",
    "cand = cand[10000:100000] # choosing records from 10,000 to 100,000 for testing purpose\n",
    "i = sorted(jo.jobId)[2]\n",
    "cand_filtered = cand[(cand.long<(jo.long[i]+0.5)) & (cand.long>(jo.long[i]-0.5)) & \n",
    "                     (cand.lat<(jo.lat[i]+0.5)) & (cand.lat>(jo.lat[i]-0.5))]\n",
    "\n",
    "\n",
    "# finding unique set of skills from all the candidates\n",
    "\n",
    "values = cand_filtered['details'].value_counts()\n",
    "values = values[values>3]\n",
    "values.index\n",
    "\n",
    "\n",
    "# calculating the similarity score for those unique set of skills\n",
    "\n",
    "for k in range(0,len(values.index)):\n",
    "    close_value.append(nlp(values.index[k]).similarity(nlp(job.title[1])))\n",
    "close_skill = values.index[close_value.index(max(close_value))]\n",
    "        \n",
    "cand_filtered = cand_filtered[cand_filtered['details'] == close_skill]  # filtering a candidate based on identified skills \n",
    "    \n",
    "for j in sorted(cand_filtered.candidateId):\n",
    "    skill_score = max(close_value) # taking the already calculated similarity score\n",
    "    dist = distance(cand.long[j],cand.lat[j],jo.long[i],jo.lat[i])\n",
    "    distance_score = 1/(pow(dist,dist*0.005))\n",
    "    df.loc[j,i]  = (skill_score*w_skill) + (distance_score*w_distance)\n",
    "    \n",
    "Id = df.loc[:,i].to_list().index(df.loc[:,i].max()) # extracting the Id of the best candidate\n",
    "print(Id)\n",
    "        \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm to match jobs with canddiates (version 4.2)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "w_skill = 0.3\n",
    "w_distance = 0.7\n",
    "\n",
    "close_skill=[]\n",
    "cand = cand_all.copy()\n",
    "cand = cand[100:100000]\n",
    "i = sorted(jo.jobId)[140]\n",
    "cand_filtered = cand[(cand.long<(jo.long[i]+0.5)) & (cand.long>(jo.long[i]-0.5)) & \n",
    "                     (cand.lat<(jo.lat[i]+0.5)) & (cand.lat>(jo.lat[i]-0.5))]\n",
    "\n",
    "values = cand_filtered['details'].value_counts()\n",
    "values = values[values>3]\n",
    "values.index\n",
    "\n",
    "for k in range(0,len(values.index)):\n",
    "    score = nlp(values.index[k]).similarity(nlp(jo.title[i])) # finding similarity score for unique skills\n",
    "    if(score>0.7):\n",
    "        close_value.append(score)\n",
    "        close_skill.append(values.index[k])\n",
    "        \n",
    "cand_filtered = cand_filtered[cand_filtered['details'].isin(close_skill)] # filtering candidates for a set of closely related skills\n",
    "    \n",
    "for j in sorted(cand_filtered.candidateId):\n",
    "    skill_score = close_value[close_skill.index(cand_filtered.details[j])] # getting the pre calculated scores for skills\n",
    "    dist = distance(cand.long[j],cand.lat[j],jo.long[i],jo.lat[i])\n",
    "    distance_score = 1/(pow(dist,dist*0.005))\n",
    "    df.loc[j,i]  = (skill_score*w_skill) + (distance_score*w_distance)\n",
    "    \n",
    "Id = df.loc[:,i].astype('float').nlargest(1000).index # finding top 1000 candidates for the given job\n",
    "display(cand_all.loc[Id,:]) # displaying top 1000 candidates\n",
    "        \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for greater than one job buiding a dataframe to store matched candidates with the respective jobs\n",
    "\n",
    "match = pd.DataFrame(index = range(0,len(job.jobId)),columns=(['jobId','candidateId']))\n",
    "match.jobId = sorted(job.jobId)\n",
    "df_array = np.array(df)\n",
    "match.index = match.jobId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing matched values in table match\n",
    "\n",
    "df1 = df.copy()\n",
    "for i in sorted(match.jobId):\n",
    "        Id = df1.columns[df1.loc[i,:].tolist().index(max(df1.loc[i,:]))]\n",
    "        match.loc[i,'candidateId'] = Id\n",
    "        df1.drop(Id,axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding candidate latitude longitude skill columns to table match for testing purpose\n",
    " \n",
    "candidates.index = candidates.candidateId\n",
    "match.index = match['candidateId']\n",
    "match['candidate_long'] = candidates.loc[match['candidateId'],'long']\n",
    "match['candidate_lat'] = candidates.loc[match['candidateId'],'lat']\n",
    "match['candidate_skill'] = candidates.loc[match['candidateId'],'details']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding job latitude longitude skill columns to table match for testing purpose\n",
    "\n",
    "job.index = job.jobId\n",
    "match.index = match['jobId']\n",
    "match['job_long'] = job.loc[match['jobId'],'long']\n",
    "match['job_lat'] = job.loc[match['jobId'],'lat']\n",
    "match['job_skill'] = job.loc[match['jobId'],'title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  adding distance and skill score to table match\n",
    "\n",
    "skill_score = []\n",
    "for i in range(0,len(match)):\n",
    "    skill_score.append(nlp(job.title[match['jobId'][i]]).similarity(nlp(candidates.details[match['candidateId'][i]])))\n",
    "    \n",
    "dist=[]\n",
    "for i in range(0,len(match)):\n",
    "    dist.append(distance(match.candidate_long[i],match.candidate_lat[i],match.job_long[i],match.job_lat[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding weighted skill score weighted distance score total score to table match\n",
    "\n",
    "match['skill_score'] = skill_score\n",
    "match['weighted_skill_score'] = np.array(skill_score)*0.3\n",
    "match['distance'] = dist\n",
    "\n",
    "dist = np.array(dist)\n",
    "match['distance_score'] = np.round(1/(pow(dist,dist*0.005)),10)\n",
    "\n",
    "match['weighted_distance_score'] = (np.round(1/(pow(dist,dist*0.005)),10))*0.7\n",
    "\n",
    "match['total_score'] = (np.array(skill_score)*0.3) + ((np.round(1/(pow(dist,dist*0.005)),10))*0.7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
